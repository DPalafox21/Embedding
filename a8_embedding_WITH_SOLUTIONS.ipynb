{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDlYPwS5U-ZN"
   },
   "source": [
    "# CS549 Machine Learning \n",
    "# Assignment 8: Word embeddings\n",
    "\n",
    "**Total points: 10**\n",
    "\n",
    "In this assignment, you will implement a simple continuous bag-of-words (CBOW) model that uses surrounding context words to predict the target word in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "mCKukd7GU-ZW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from a8_utils import build_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEoUA2lmU-ZY"
   },
   "source": [
    "## Task 1. Prepare data\n",
    "**3 points**\n",
    "\n",
    "In this task, you should prepare your data, which is a list of tuples. Each tuple has two elements: a list of context words, and the target word.\n",
    "Here both context words and target word are represented by word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssaqzepWU-ZZ",
    "outputId": "54189092-6c11-480c-bc1f-9e96631f32ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 3  # Define the context size. Default value 3, which means the context includes 3 words to the left, 3 to the right\n",
    "\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "vocab = build_vocab(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = list(vocab)\n",
    "word_indices = [word_to_idx[w] for w in raw_text]\n",
    "\n",
    "def prepare_data(word_indices):\n",
    "    data = []\n",
    "    for i in range(CONTEXT_SIZE, len(word_indices) - CONTEXT_SIZE):\n",
    "\n",
    "        #### START YOUR CODE ####\n",
    "        # Hint: You can intialize context to an empty list\n",
    "        # and then use a for loop to append elements to context propoerly.\n",
    "        context = []\n",
    "        target = i\n",
    "        for j in range(i-CONTEXT_SIZE,i):\n",
    "          context.append(j)\n",
    "        for j in range(i+1,i+CONTEXT_SIZE+1):\n",
    "          context.append(j)\n",
    "        #### END YOUR CODE ####\n",
    "\n",
    "        data.append((context, target))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTfC3UABU-Za",
    "outputId": "a1652e95-7d49-461f-fbec-0241809a3cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0]: ([0, 1, 2, 4, 5, 6], 3)\n",
      "context words: ['We', 'are', 'about', 'study', 'the', 'idea']\n",
      "target word: to\n"
     ]
    }
   ],
   "source": [
    "# Test Task 1. Do not change the code below.\n",
    "data = prepare_data(word_indices)\n",
    "print('data[0]:', data[0])\n",
    "ctx, tgt = data[0]\n",
    "print('context words:', [idx_to_word[c] for c in ctx])\n",
    "print('target word:', idx_to_word[tgt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlZ-95z3U-Zb"
   },
   "source": [
    "## Expected output\n",
    "\n",
    "|&nbsp;|&nbsp;|\n",
    "|--|--|\n",
    "|data\\[0\\]: |(\\[0, 1, 2, 4, 5, 6\\], 3)|\n",
    "|context words: |\\['We', 'are', 'about', 'study', 'the', 'idea'\\]|\n",
    "|target word: | to|\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3JRB_IjU-Zc"
   },
   "source": [
    "## Task 2: Implement a CBOW model\n",
    "\n",
    "**4 points**\n",
    "\n",
    "In this task, you will implement a CBOW model. In the `__init__()` method, define the size of `self.embeddings` and `self.linear` properly.\n",
    "\n",
    "The `self.linear` takes the average embeddings of all context words as input, and the output size is `vocab_size`.\n",
    "It is followed by a softmax activation (`nn.LogSoftmax`).\n",
    "\n",
    "The `forward()` method has a input argument `inputs`, which is the context word indices (in a `torch.long` tensor).\n",
    "You should get the embeddings of all context words, and compute the average emebdding (into the `embeds` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "23bcq83eU-Ze"
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        #### START YOUR CODE ####\n",
    "        self.embeddings = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim,vocab_size)\n",
    "        #### END YOUR CODE ####\n",
    "        \n",
    "        self.act = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #### START YOUR CODE ####\n",
    "        embeds = torch.sum(self.embeddings(inputs),dim=0).view(1,-1)\n",
    "        #### END YOUR CODE ####\n",
    "        \n",
    "        out = self.linear(embeds)\n",
    "        out = self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAFbOv6pU-Zf",
    "outputId": "fb8533d9-83a3-4072-fc6d-f1b4a28d9f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output.shape torch.Size([1, 10])\n",
      "test_output tensor([[-1.6878, -4.2108, -5.0252, -2.9802, -3.1362, -1.5436, -1.4120, -3.2485,\n",
      "         -1.6490, -4.5009]])\n"
     ]
    }
   ],
   "source": [
    "# Test Task 2. Do not change the code blow\n",
    "torch.manual_seed(0)\n",
    "\n",
    "m = CBOW(10, 20)\n",
    "test_input = torch.tensor([1,2,3], dtype=torch.long)\n",
    "test_output = m(test_input)\n",
    "\n",
    "print('test_output.shape', test_output.shape)\n",
    "print('test_output', test_output.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pV1dXWaU-Zg"
   },
   "source": [
    "### Expected output\n",
    "|&nbsp;|&nbsp;|\n",
    "|--|--|\n",
    "|test_output.shape| torch.Size(\\[1, 10\\])|\n",
    "|test_output|tensor(\\[\\[-1.6878, -4.2108, -5.0252, -2.9802, -3.1362, -1.5436, -1.4120, -3.2485, -1.6490, -4.5009\\]\\])|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sErOu2qwU-Zh"
   },
   "source": [
    "## Task 3. Training loop\n",
    "**2 points**\n",
    "\n",
    "In this task, you will complete the training loop. \n",
    "\n",
    "You should create `ctx_tensor` and `tgt_tensor` out of `ctx` and `tgt`, respectively. *Hint*: you need to put `tgt` to a list before craeting the `tgt_tensor`, so that the resulting tensor is of the correct dimension that is acceptable to `nn.NLLLoss()`.\n",
    "\n",
    "`ctx_tensor` is used to compute `output`. `loss_function()` is called upon `output` and `tgt_tensor` to compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqRwHBswU-Zi",
    "outputId": "d80fdea6-af02-4ab5-f642-c1e6d8491ed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss within epoch 5:  128.23919677734375\n",
      "Loss within epoch 10:  58.24411392211914\n",
      "Loss within epoch 15:  31.39347267150879\n",
      "Loss within epoch 20:  20.52120590209961\n",
      "Loss within epoch 25:  15.03664779663086\n",
      "Loss within epoch 30:  11.805497169494629\n",
      "Loss within epoch 35:  9.696945190429688\n",
      "Loss within epoch 40:  8.219900131225586\n",
      "Loss within epoch 45:  7.130527496337891\n",
      "Loss within epoch 50:  6.295182704925537\n",
      "Loss within epoch 55:  5.634889125823975\n",
      "Loss within epoch 60:  5.100137710571289\n",
      "Loss within epoch 65:  4.658383369445801\n",
      "Loss within epoch 70:  4.287387847900391\n",
      "Loss within epoch 75:  3.9714505672454834\n",
      "Loss within epoch 80:  3.69918155670166\n",
      "Loss within epoch 85:  3.462122678756714\n",
      "Loss within epoch 90:  3.2538628578186035\n",
      "Loss within epoch 95:  3.0694527626037598\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "EMDEDDING_DIM = 100\n",
    "model = CBOW(65, EMDEDDING_DIM)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "\n",
    "    for ctx, tgt in data:\n",
    "        #### START YOUR CODE ####\n",
    "        #print(ctx,tgt)\n",
    "        ctx_tensor = torch.tensor(ctx,dtype=torch.long) # Hint: the tensor type should be torch.long\n",
    "        tgt_tensor = torch.tensor([tgt])\n",
    "        output = model(ctx_tensor)\n",
    "        # The try...except code is to help you debug. You can leave them unchanged. \n",
    "        try:\n",
    "          #print(loss_function(output,tgt_tensor))\n",
    "          total_loss += loss_function(output,tgt_tensor)\n",
    "        except Exception:\n",
    "            print(ctx_tensor)\n",
    "            print(tgt_tensor)\n",
    "            raise\n",
    "        #### END YOUR CODE ####\n",
    "\n",
    "    #optimize at the end of each epoch\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print training information\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        print(f'Loss within epoch {epoch}: ', total_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo0kLmjUU-Zi"
   },
   "source": [
    "### Expected output:\n",
    "\n",
    "You should obeserve the loss decreasing from 100+ (at epoch 5) to around 3.x (at epoch 95).\n",
    "The absolute values do not matter.\n",
    "\n",
    "<!-- |&nbsp;|&nbsp;|\n",
    "|--|--|\n",
    "|Loss within epoch 5: | 138.33709716796875|\n",
    "|Loss within epoch 10: | 70.50218963623047|\n",
    "|Loss within epoch 15: | 38.877227783203125|\n",
    "|Loss within epoch 20: | 25.064970016479492|\n",
    "|Loss within epoch 25: | 18.110904693603516|\n",
    "|Loss within epoch 30: | 14.05634880065918|\n",
    "|Loss within epoch 35: | 11.44089126586914|\n",
    "|Loss within epoch 40: | 9.62782096862793|\n",
    "|Loss within epoch 45: | 8.302525520324707|\n",
    "|Loss within epoch 50: | 7.293947219848633|\n",
    "|Loss within epoch 55: | 6.501856327056885|\n",
    "|Loss within epoch 60: | 5.863919734954834|\n",
    "|Loss within epoch 65: | 5.339460372924805|\n",
    "|Loss within epoch 70: | 4.900869846343994|\n",
    "|Loss within epoch 75: | 4.528764247894287|\n",
    "|Loss within epoch 80: | 4.209164619445801|\n",
    "|Loss within epoch 85: | 3.9317333698272705|\n",
    "|Loss within epoch 90: | 3.688669443130493|\n",
    "|Loss within epoch 95: | 3.473975896835327| -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaH_xuwVU-Zj"
   },
   "source": [
    "## Task 4\n",
    "**1 point**\n",
    "\n",
    "In this final task, you will need to find the maximum index among the model output. *Hint*: use `torch.argmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "2BSxvldLU-Zk"
   },
   "outputs": [],
   "source": [
    "def get_predicted_word(model_output, idx_to_word):\n",
    "    #### START YOUR CODE ####\n",
    "    idx = torch.argmax(model_output)\n",
    "    #### END YOUR CODE ####\n",
    "\n",
    "    return idx_to_word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyY5fFlrU-Zk",
    "outputId": "5633a5df-6d58-476d-9092-cd273597ede8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted word is: \"process\"\n"
     ]
    }
   ],
   "source": [
    "# Test Task 4. Do not change the code blow\n",
    "ctx_words = 'evolution of a is directed by'.split()\n",
    "ctx_indices = [word_to_idx[w] for w in ctx_words]\n",
    "ctx_tensor = torch.tensor(ctx_indices, dtype=torch.long)\n",
    "\n",
    "out = model(ctx_tensor)\n",
    "pred = get_predicted_word(out, idx_to_word)\n",
    "print(f'The predicted word is: \\\"{pred}\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhRI_gm8U-Zl"
   },
   "source": [
    "### Expected output\n",
    "\n",
    "|&nbsp;|&nbsp;|\n",
    "|--|--|\n",
    "|The predicted word is: |\"process\"|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXCg6QAzU-Zl"
   },
   "source": [
    "## Congratulation!\n",
    "Congratulations! You have now understood how to use word embeddings for some basic NLP tasks!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "a8_embedding_WITH_SOLUTIONS.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "25f78cd986e649f5a1fa57f7be9a497a8fd91952316ec3e436af56ac9acfc630"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
